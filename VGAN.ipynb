{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## VGAN"
      ],
      "metadata": {
        "id": "PDMHEHt7cFXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cyqpCzT0p4cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9c2720-465a-4b43-e6fb-dac1d1064a20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zs4Enj8wCAe9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Device \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Dy-PPhtoCDss"
      },
      "outputs": [],
      "source": [
        "# Hyper parameters\n",
        "latent_size = 100\n",
        "hidden_size = 128\n",
        "image_size = 32      ## 일반적으로 학습이 잘 되는 size는 64x64라고 했으나, RAM down으로 인해 32x32를 사용함\n",
        "num_epochs = 150\n",
        "batch_size = 256\n",
        "sample_dir = '/content/drive/MyDrive/Colab_Notebooks/4-1_DL/result/VGAN_IS_car/'   ## fake images를 저장할 경로"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data load\n",
        "!unzip '/content/drive/MyDrive/Colab_Notebooks/4-1_DL/cars_images.zip' -d /content/data/"
      ],
      "metadata": {
        "id": "_fa_mSctsbUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adcc074-33bd-41e2-c3e1-36e7123ffa5e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Colab_Notebooks/4-1_DL/cars_images.zip\n",
            "replace /content/data/cars_images/Acura_ILX_2013_28_16_110_15_4_70_55_179_39_FWD_5_4_4dr_Mro.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset composition\n",
        "ddir = '/content/data/'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "         transforms.Resize((image_size,image_size)),   \n",
        "         transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5],std=[0.5])\n",
        "        ])\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder(ddir, transform=transform)\n",
        "print(dataset)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsJSWEdWyssO",
        "outputId": "a8730f96-80bb-4ed0-9e9b-86bde582e19b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 8960\n",
            "    Root location: /content/data/\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(32, 32), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.5], std=[0.5])\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GI6-cbhTCO3U"
      },
      "outputs": [],
      "source": [
        "# Discriminator\n",
        "D = nn.Sequential(\n",
        "    nn.Conv2d(3, hidden_size, kernel_size=3, stride=2),   ## input은 color image 이므로 in_channels=3, Discriminator는 Encoder처럼 작동하므로 stride=2 (downsampling)\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(hidden_size, hidden_size, kernel_size=3, stride=2),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(hidden_size, hidden_size, kernel_size=3, stride=2),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(hidden_size, 1, kernel_size=3, stride=2),   \n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid()  ## 0 ~ 1로 정규화하여, label(0 또는 1)과의 loss를 구함\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SdKQyk-QCQGB"
      },
      "outputs": [],
      "source": [
        "# Generator \n",
        "G = nn.Sequential(\n",
        "    nn.ConvTranspose2d(latent_size, hidden_size, kernel_size=3, stride=2),   ## input은 latent vector 이므로 in_channels=latent vector의 dimension, Generator Decoder처럼 작동하므로 stride=2 (upsampling)\n",
        "    nn.ReLU(),\n",
        "    nn.ConvTranspose2d(hidden_size, hidden_size, kernel_size=3,stride=2),\n",
        "    nn.ReLU(),\n",
        "    nn.ConvTranspose2d(hidden_size, hidden_size, kernel_size=3,stride=2),\n",
        "    nn.ReLU(),\n",
        "    nn.ConvTranspose2d(hidden_size, 3, kernel_size=3,stride=2),   ## output은 Discriminator의 input으로 들어가는 fake image 이므로 out_channels=3\n",
        "    nn.Tanh()    ## -1 ~ 1로 정규화하여, 일반적인 이미지값 범위를 동일하게 함\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "m35sY6WQCUqu"
      },
      "outputs": [],
      "source": [
        "# Device setting\n",
        "D = D.to(device)\n",
        "G = G.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Yvgawgp5CWlW"
      },
      "outputs": [],
      "source": [
        "# Loss\n",
        "criterion = nn.BCELoss()   ##  Binary Cross Entropy\n",
        "\n",
        "# Optimizer\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rxTQ0__4Cc-a"
      },
      "outputs": [],
      "source": [
        "# Set prob\n",
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)\n",
        "\n",
        "# Set grad\n",
        "def reset_grad():\n",
        "    d_optimizer.zero_grad()\n",
        "    g_optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ac8NUJ5CCgoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d231a9d6-88d9-4c80-a0d4-61f2f47158f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/150], Step [35/35], d_loss: 0.0665, g_loss: 3.2083, D(x): 0.99, D(G(z)): 0.05\n",
            "Epoch [1/150], Step [35/35], d_loss: 0.0083, g_loss: 6.9298, D(x): 1.00, D(G(z)): 0.01\n",
            "Epoch [2/150], Step [35/35], d_loss: 0.0183, g_loss: 4.1889, D(x): 0.99, D(G(z)): 0.00\n",
            "Epoch [3/150], Step [35/35], d_loss: 0.0027, g_loss: 6.6739, D(x): 1.00, D(G(z)): 0.00\n",
            "Epoch [4/150], Step [35/35], d_loss: 0.0039, g_loss: 6.9248, D(x): 1.00, D(G(z)): 0.00\n",
            "Epoch [5/150], Step [35/35], d_loss: 0.0045, g_loss: 6.3357, D(x): 1.00, D(G(z)): 0.00\n",
            "Epoch [6/150], Step [35/35], d_loss: 0.3264, g_loss: 13.9510, D(x): 0.99, D(G(z)): 0.26\n",
            "Epoch [7/150], Step [35/35], d_loss: 0.0630, g_loss: 6.6192, D(x): 0.98, D(G(z)): 0.00\n",
            "Epoch [8/150], Step [35/35], d_loss: 0.1204, g_loss: 4.5725, D(x): 0.94, D(G(z)): 0.01\n",
            "Epoch [9/150], Step [35/35], d_loss: 0.1058, g_loss: 3.9920, D(x): 0.94, D(G(z)): 0.01\n",
            "Epoch [10/150], Step [35/35], d_loss: 0.0418, g_loss: 4.6020, D(x): 0.97, D(G(z)): 0.01\n",
            "Epoch [11/150], Step [35/35], d_loss: 0.0229, g_loss: 5.2985, D(x): 0.98, D(G(z)): 0.00\n",
            "Epoch [12/150], Step [35/35], d_loss: 0.0152, g_loss: 5.6676, D(x): 0.99, D(G(z)): 0.00\n",
            "Epoch [13/150], Step [35/35], d_loss: 0.0264, g_loss: 5.2552, D(x): 0.98, D(G(z)): 0.00\n",
            "Epoch [14/150], Step [35/35], d_loss: 0.2195, g_loss: 3.3623, D(x): 0.92, D(G(z)): 0.02\n",
            "Epoch [15/150], Step [35/35], d_loss: 0.5690, g_loss: 1.4052, D(x): 0.79, D(G(z)): 0.09\n",
            "Epoch [16/150], Step [35/35], d_loss: 0.6696, g_loss: 1.8215, D(x): 0.76, D(G(z)): 0.12\n",
            "Epoch [17/150], Step [35/35], d_loss: 0.5620, g_loss: 2.1667, D(x): 0.77, D(G(z)): 0.12\n",
            "Epoch [18/150], Step [35/35], d_loss: 1.0006, g_loss: 1.5462, D(x): 0.68, D(G(z)): 0.14\n",
            "Epoch [19/150], Step [35/35], d_loss: 0.7216, g_loss: 1.6777, D(x): 0.74, D(G(z)): 0.17\n",
            "Epoch [20/150], Step [35/35], d_loss: 0.9343, g_loss: 1.3451, D(x): 0.67, D(G(z)): 0.23\n",
            "Epoch [21/150], Step [35/35], d_loss: 1.0710, g_loss: 1.4043, D(x): 0.67, D(G(z)): 0.33\n",
            "Epoch [22/150], Step [35/35], d_loss: 0.9944, g_loss: 1.2074, D(x): 0.63, D(G(z)): 0.26\n",
            "Epoch [23/150], Step [35/35], d_loss: 1.1152, g_loss: 1.4221, D(x): 0.61, D(G(z)): 0.35\n",
            "Epoch [24/150], Step [35/35], d_loss: 0.9720, g_loss: 1.2757, D(x): 0.62, D(G(z)): 0.26\n",
            "Epoch [25/150], Step [35/35], d_loss: 1.0563, g_loss: 1.3814, D(x): 0.62, D(G(z)): 0.32\n",
            "Epoch [26/150], Step [35/35], d_loss: 0.9850, g_loss: 1.4026, D(x): 0.62, D(G(z)): 0.29\n",
            "Epoch [27/150], Step [35/35], d_loss: 1.0688, g_loss: 1.4266, D(x): 0.63, D(G(z)): 0.32\n",
            "Epoch [28/150], Step [35/35], d_loss: 0.9765, g_loss: 1.4532, D(x): 0.62, D(G(z)): 0.30\n",
            "Epoch [29/150], Step [35/35], d_loss: 1.1938, g_loss: 1.2153, D(x): 0.56, D(G(z)): 0.37\n",
            "Epoch [30/150], Step [35/35], d_loss: 0.9706, g_loss: 1.6064, D(x): 0.65, D(G(z)): 0.35\n",
            "Epoch [31/150], Step [35/35], d_loss: 1.0535, g_loss: 1.4345, D(x): 0.63, D(G(z)): 0.38\n",
            "Epoch [32/150], Step [35/35], d_loss: 1.0799, g_loss: 1.4866, D(x): 0.62, D(G(z)): 0.39\n",
            "Epoch [33/150], Step [35/35], d_loss: 1.0179, g_loss: 1.5410, D(x): 0.61, D(G(z)): 0.32\n",
            "Epoch [34/150], Step [35/35], d_loss: 0.9901, g_loss: 1.3974, D(x): 0.66, D(G(z)): 0.40\n",
            "Epoch [35/150], Step [35/35], d_loss: 1.0326, g_loss: 1.4377, D(x): 0.63, D(G(z)): 0.37\n",
            "Epoch [36/150], Step [35/35], d_loss: 1.0691, g_loss: 1.3541, D(x): 0.57, D(G(z)): 0.31\n",
            "Epoch [37/150], Step [35/35], d_loss: 0.9553, g_loss: 1.6496, D(x): 0.63, D(G(z)): 0.34\n",
            "Epoch [38/150], Step [35/35], d_loss: 1.0102, g_loss: 1.5375, D(x): 0.67, D(G(z)): 0.40\n",
            "Epoch [39/150], Step [35/35], d_loss: 0.9502, g_loss: 1.3917, D(x): 0.62, D(G(z)): 0.31\n",
            "Epoch [40/150], Step [35/35], d_loss: 0.9452, g_loss: 1.5063, D(x): 0.62, D(G(z)): 0.30\n",
            "Epoch [41/150], Step [35/35], d_loss: 0.8894, g_loss: 1.5927, D(x): 0.61, D(G(z)): 0.23\n",
            "Epoch [42/150], Step [35/35], d_loss: 0.9267, g_loss: 1.6366, D(x): 0.69, D(G(z)): 0.37\n",
            "Epoch [43/150], Step [35/35], d_loss: 0.8658, g_loss: 1.4071, D(x): 0.66, D(G(z)): 0.31\n",
            "Epoch [44/150], Step [35/35], d_loss: 0.7967, g_loss: 1.7790, D(x): 0.69, D(G(z)): 0.29\n",
            "Epoch [45/150], Step [35/35], d_loss: 1.0428, g_loss: 1.6254, D(x): 0.65, D(G(z)): 0.40\n",
            "Epoch [46/150], Step [35/35], d_loss: 0.9006, g_loss: 1.5691, D(x): 0.68, D(G(z)): 0.35\n",
            "Epoch [47/150], Step [35/35], d_loss: 0.8889, g_loss: 1.5653, D(x): 0.69, D(G(z)): 0.36\n",
            "Epoch [48/150], Step [35/35], d_loss: 0.9738, g_loss: 1.6103, D(x): 0.68, D(G(z)): 0.40\n",
            "Epoch [49/150], Step [35/35], d_loss: 0.9520, g_loss: 1.4885, D(x): 0.66, D(G(z)): 0.37\n",
            "Epoch [50/150], Step [35/35], d_loss: 0.8150, g_loss: 1.5104, D(x): 0.68, D(G(z)): 0.30\n",
            "Epoch [51/150], Step [35/35], d_loss: 0.9358, g_loss: 1.5941, D(x): 0.69, D(G(z)): 0.38\n",
            "Epoch [52/150], Step [35/35], d_loss: 0.9242, g_loss: 1.6072, D(x): 0.57, D(G(z)): 0.20\n",
            "Epoch [53/150], Step [35/35], d_loss: 0.9377, g_loss: 1.5051, D(x): 0.69, D(G(z)): 0.39\n",
            "Epoch [54/150], Step [35/35], d_loss: 0.8538, g_loss: 1.5597, D(x): 0.71, D(G(z)): 0.35\n",
            "Epoch [55/150], Step [35/35], d_loss: 0.7799, g_loss: 1.7684, D(x): 0.73, D(G(z)): 0.33\n",
            "Epoch [56/150], Step [35/35], d_loss: 0.8701, g_loss: 1.5027, D(x): 0.70, D(G(z)): 0.34\n",
            "Epoch [57/150], Step [35/35], d_loss: 0.7940, g_loss: 1.5595, D(x): 0.72, D(G(z)): 0.33\n",
            "Epoch [58/150], Step [35/35], d_loss: 0.8348, g_loss: 1.3811, D(x): 0.69, D(G(z)): 0.32\n",
            "Epoch [59/150], Step [35/35], d_loss: 0.8558, g_loss: 1.6885, D(x): 0.73, D(G(z)): 0.37\n",
            "Epoch [60/150], Step [35/35], d_loss: 0.7311, g_loss: 1.6705, D(x): 0.76, D(G(z)): 0.33\n",
            "Epoch [61/150], Step [35/35], d_loss: 0.9107, g_loss: 1.3716, D(x): 0.63, D(G(z)): 0.29\n",
            "Epoch [62/150], Step [35/35], d_loss: 0.9380, g_loss: 1.2154, D(x): 0.63, D(G(z)): 0.32\n",
            "Epoch [63/150], Step [35/35], d_loss: 1.0046, g_loss: 1.3147, D(x): 0.65, D(G(z)): 0.37\n",
            "Epoch [64/150], Step [35/35], d_loss: 0.9018, g_loss: 1.3170, D(x): 0.67, D(G(z)): 0.33\n",
            "Epoch [65/150], Step [35/35], d_loss: 0.9291, g_loss: 1.3392, D(x): 0.64, D(G(z)): 0.30\n",
            "Epoch [66/150], Step [35/35], d_loss: 0.8112, g_loss: 1.6469, D(x): 0.75, D(G(z)): 0.35\n",
            "Epoch [67/150], Step [35/35], d_loss: 0.9956, g_loss: 0.9920, D(x): 0.56, D(G(z)): 0.24\n",
            "Epoch [68/150], Step [35/35], d_loss: 1.0428, g_loss: 1.1715, D(x): 0.61, D(G(z)): 0.33\n",
            "Epoch [69/150], Step [35/35], d_loss: 1.0135, g_loss: 1.1467, D(x): 0.61, D(G(z)): 0.31\n",
            "Epoch [70/150], Step [35/35], d_loss: 1.0481, g_loss: 1.1034, D(x): 0.62, D(G(z)): 0.35\n",
            "Epoch [71/150], Step [35/35], d_loss: 0.9800, g_loss: 1.3354, D(x): 0.65, D(G(z)): 0.34\n",
            "Epoch [72/150], Step [35/35], d_loss: 0.9244, g_loss: 1.3527, D(x): 0.67, D(G(z)): 0.35\n",
            "Epoch [73/150], Step [35/35], d_loss: 0.9072, g_loss: 1.1317, D(x): 0.60, D(G(z)): 0.24\n",
            "Epoch [74/150], Step [35/35], d_loss: 0.8701, g_loss: 1.1977, D(x): 0.65, D(G(z)): 0.29\n",
            "Epoch [75/150], Step [35/35], d_loss: 0.9886, g_loss: 1.1784, D(x): 0.61, D(G(z)): 0.30\n",
            "Epoch [76/150], Step [35/35], d_loss: 0.9423, g_loss: 1.1892, D(x): 0.65, D(G(z)): 0.33\n",
            "Epoch [77/150], Step [35/35], d_loss: 0.9179, g_loss: 1.3858, D(x): 0.70, D(G(z)): 0.37\n",
            "Epoch [78/150], Step [35/35], d_loss: 0.8240, g_loss: 1.4652, D(x): 0.72, D(G(z)): 0.34\n",
            "Epoch [79/150], Step [35/35], d_loss: 0.8523, g_loss: 1.3698, D(x): 0.67, D(G(z)): 0.30\n",
            "Epoch [80/150], Step [35/35], d_loss: 0.9163, g_loss: 1.4601, D(x): 0.69, D(G(z)): 0.37\n",
            "Epoch [81/150], Step [35/35], d_loss: 0.8096, g_loss: 1.4577, D(x): 0.73, D(G(z)): 0.33\n",
            "Epoch [82/150], Step [35/35], d_loss: 0.8723, g_loss: 1.3815, D(x): 0.68, D(G(z)): 0.30\n",
            "Epoch [83/150], Step [35/35], d_loss: 0.8281, g_loss: 1.1628, D(x): 0.68, D(G(z)): 0.29\n",
            "Epoch [84/150], Step [35/35], d_loss: 0.8449, g_loss: 1.3415, D(x): 0.70, D(G(z)): 0.32\n",
            "Epoch [85/150], Step [35/35], d_loss: 0.8029, g_loss: 1.2848, D(x): 0.70, D(G(z)): 0.30\n",
            "Epoch [86/150], Step [35/35], d_loss: 0.8203, g_loss: 1.5438, D(x): 0.73, D(G(z)): 0.34\n",
            "Epoch [87/150], Step [35/35], d_loss: 0.8324, g_loss: 1.6666, D(x): 0.73, D(G(z)): 0.34\n",
            "Epoch [88/150], Step [35/35], d_loss: 0.7732, g_loss: 1.3943, D(x): 0.69, D(G(z)): 0.25\n",
            "Epoch [89/150], Step [35/35], d_loss: 0.8134, g_loss: 1.5012, D(x): 0.71, D(G(z)): 0.30\n",
            "Epoch [90/150], Step [35/35], d_loss: 0.7726, g_loss: 1.8007, D(x): 0.78, D(G(z)): 0.34\n",
            "Epoch [91/150], Step [35/35], d_loss: 0.7767, g_loss: 1.5478, D(x): 0.76, D(G(z)): 0.34\n",
            "Epoch [92/150], Step [35/35], d_loss: 0.7527, g_loss: 1.4470, D(x): 0.75, D(G(z)): 0.31\n",
            "Epoch [93/150], Step [35/35], d_loss: 0.8153, g_loss: 1.6782, D(x): 0.76, D(G(z)): 0.34\n",
            "Epoch [94/150], Step [35/35], d_loss: 0.7628, g_loss: 1.8830, D(x): 0.79, D(G(z)): 0.36\n",
            "Epoch [95/150], Step [35/35], d_loss: 0.8053, g_loss: 1.6645, D(x): 0.77, D(G(z)): 0.37\n",
            "Epoch [96/150], Step [35/35], d_loss: 0.8422, g_loss: 1.5718, D(x): 0.79, D(G(z)): 0.39\n",
            "Epoch [97/150], Step [35/35], d_loss: 0.7811, g_loss: 1.5013, D(x): 0.77, D(G(z)): 0.34\n",
            "Epoch [98/150], Step [35/35], d_loss: 0.8057, g_loss: 1.4047, D(x): 0.75, D(G(z)): 0.35\n",
            "Epoch [99/150], Step [35/35], d_loss: 0.8220, g_loss: 1.5734, D(x): 0.76, D(G(z)): 0.36\n",
            "Epoch [100/150], Step [35/35], d_loss: 0.7770, g_loss: 1.4849, D(x): 0.77, D(G(z)): 0.34\n",
            "Epoch [101/150], Step [35/35], d_loss: 0.7678, g_loss: 1.5665, D(x): 0.76, D(G(z)): 0.32\n",
            "Epoch [102/150], Step [35/35], d_loss: 0.7549, g_loss: 1.5738, D(x): 0.76, D(G(z)): 0.32\n",
            "Epoch [103/150], Step [35/35], d_loss: 0.8114, g_loss: 1.7548, D(x): 0.78, D(G(z)): 0.37\n",
            "Epoch [104/150], Step [35/35], d_loss: 0.7974, g_loss: 1.5166, D(x): 0.74, D(G(z)): 0.32\n",
            "Epoch [105/150], Step [35/35], d_loss: 0.7499, g_loss: 1.6666, D(x): 0.79, D(G(z)): 0.35\n",
            "Epoch [106/150], Step [35/35], d_loss: 0.7391, g_loss: 1.5177, D(x): 0.75, D(G(z)): 0.30\n",
            "Epoch [107/150], Step [35/35], d_loss: 0.7713, g_loss: 1.6900, D(x): 0.78, D(G(z)): 0.34\n",
            "Epoch [108/150], Step [35/35], d_loss: 0.7671, g_loss: 1.7193, D(x): 0.79, D(G(z)): 0.35\n",
            "Epoch [109/150], Step [35/35], d_loss: 0.7485, g_loss: 1.4738, D(x): 0.73, D(G(z)): 0.28\n",
            "Epoch [110/150], Step [35/35], d_loss: 0.7919, g_loss: 1.7914, D(x): 0.79, D(G(z)): 0.37\n",
            "Epoch [111/150], Step [35/35], d_loss: 0.7678, g_loss: 1.6453, D(x): 0.80, D(G(z)): 0.37\n",
            "Epoch [112/150], Step [35/35], d_loss: 0.8161, g_loss: 1.6020, D(x): 0.78, D(G(z)): 0.37\n",
            "Epoch [113/150], Step [35/35], d_loss: 0.7709, g_loss: 1.5811, D(x): 0.79, D(G(z)): 0.36\n",
            "Epoch [114/150], Step [35/35], d_loss: 0.8439, g_loss: 1.6417, D(x): 0.75, D(G(z)): 0.36\n",
            "Epoch [115/150], Step [35/35], d_loss: 0.7967, g_loss: 1.5209, D(x): 0.74, D(G(z)): 0.32\n",
            "Epoch [116/150], Step [35/35], d_loss: 0.7694, g_loss: 1.5843, D(x): 0.76, D(G(z)): 0.32\n",
            "Epoch [117/150], Step [35/35], d_loss: 0.7786, g_loss: 1.3275, D(x): 0.70, D(G(z)): 0.26\n",
            "Epoch [118/150], Step [35/35], d_loss: 0.7751, g_loss: 1.4594, D(x): 0.76, D(G(z)): 0.32\n",
            "Epoch [119/150], Step [35/35], d_loss: 0.7776, g_loss: 1.3729, D(x): 0.72, D(G(z)): 0.28\n",
            "Epoch [120/150], Step [35/35], d_loss: 0.8553, g_loss: 1.6919, D(x): 0.77, D(G(z)): 0.38\n",
            "Epoch [121/150], Step [35/35], d_loss: 0.8415, g_loss: 1.4243, D(x): 0.71, D(G(z)): 0.30\n",
            "Epoch [122/150], Step [35/35], d_loss: 0.8480, g_loss: 1.3508, D(x): 0.67, D(G(z)): 0.27\n",
            "Epoch [123/150], Step [35/35], d_loss: 0.8362, g_loss: 1.2525, D(x): 0.69, D(G(z)): 0.29\n",
            "Epoch [124/150], Step [35/35], d_loss: 0.8062, g_loss: 1.5451, D(x): 0.75, D(G(z)): 0.33\n",
            "Epoch [125/150], Step [35/35], d_loss: 0.7944, g_loss: 1.3883, D(x): 0.71, D(G(z)): 0.26\n",
            "Epoch [126/150], Step [35/35], d_loss: 0.7715, g_loss: 1.4528, D(x): 0.76, D(G(z)): 0.32\n",
            "Epoch [127/150], Step [35/35], d_loss: 0.8329, g_loss: 1.7426, D(x): 0.78, D(G(z)): 0.38\n",
            "Epoch [128/150], Step [35/35], d_loss: 0.8060, g_loss: 1.2334, D(x): 0.68, D(G(z)): 0.25\n",
            "Epoch [129/150], Step [35/35], d_loss: 0.7630, g_loss: 1.2913, D(x): 0.70, D(G(z)): 0.25\n",
            "Epoch [130/150], Step [35/35], d_loss: 0.7994, g_loss: 1.6645, D(x): 0.77, D(G(z)): 0.34\n",
            "Epoch [131/150], Step [35/35], d_loss: 0.7541, g_loss: 1.4430, D(x): 0.75, D(G(z)): 0.30\n",
            "Epoch [132/150], Step [35/35], d_loss: 0.7863, g_loss: 1.5959, D(x): 0.76, D(G(z)): 0.33\n",
            "Epoch [133/150], Step [35/35], d_loss: 0.7920, g_loss: 1.1149, D(x): 0.67, D(G(z)): 0.23\n",
            "Epoch [134/150], Step [35/35], d_loss: 0.7506, g_loss: 1.6293, D(x): 0.75, D(G(z)): 0.31\n",
            "Epoch [135/150], Step [35/35], d_loss: 0.7673, g_loss: 1.3871, D(x): 0.73, D(G(z)): 0.28\n",
            "Epoch [136/150], Step [35/35], d_loss: 0.7243, g_loss: 1.4238, D(x): 0.74, D(G(z)): 0.26\n",
            "Epoch [137/150], Step [35/35], d_loss: 0.7740, g_loss: 1.6087, D(x): 0.77, D(G(z)): 0.33\n",
            "Epoch [138/150], Step [35/35], d_loss: 0.7907, g_loss: 1.5775, D(x): 0.76, D(G(z)): 0.33\n",
            "Epoch [139/150], Step [35/35], d_loss: 0.7988, g_loss: 1.5447, D(x): 0.74, D(G(z)): 0.32\n",
            "Epoch [140/150], Step [35/35], d_loss: 0.7893, g_loss: 1.6930, D(x): 0.78, D(G(z)): 0.36\n",
            "Epoch [141/150], Step [35/35], d_loss: 0.8155, g_loss: 1.5549, D(x): 0.75, D(G(z)): 0.34\n",
            "Epoch [142/150], Step [35/35], d_loss: 0.7552, g_loss: 1.4200, D(x): 0.73, D(G(z)): 0.27\n",
            "Epoch [143/150], Step [35/35], d_loss: 0.7953, g_loss: 1.6027, D(x): 0.76, D(G(z)): 0.34\n",
            "Epoch [144/150], Step [35/35], d_loss: 0.8498, g_loss: 1.7167, D(x): 0.80, D(G(z)): 0.40\n",
            "Epoch [145/150], Step [35/35], d_loss: 0.8286, g_loss: 1.6386, D(x): 0.79, D(G(z)): 0.38\n",
            "Epoch [146/150], Step [35/35], d_loss: 0.7787, g_loss: 1.4168, D(x): 0.73, D(G(z)): 0.29\n",
            "Epoch [147/150], Step [35/35], d_loss: 0.7977, g_loss: 1.4914, D(x): 0.74, D(G(z)): 0.31\n",
            "Epoch [148/150], Step [35/35], d_loss: 0.8224, g_loss: 1.7434, D(x): 0.79, D(G(z)): 0.37\n",
            "Epoch [149/150], Step [35/35], d_loss: 0.7994, g_loss: 1.6013, D(x): 0.72, D(G(z)): 0.29\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "total_step = len(data_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, _) in enumerate(data_loader):\n",
        "    images = images.to(device)\n",
        "    \n",
        "    # Labels\n",
        "    real_labels = torch.ones(batch_size, 1).to(device)    ## real_labels == 1\n",
        "    fake_labels = torch.zeros(batch_size, 1).to(device)   ## fake_labels == 0\n",
        "\n",
        "    # ================================================================== #\n",
        "    #                      Train the discriminator                       #\n",
        "    # ================================================================== #\n",
        "    # (1) real data끼리 묶어서 D를 학습\n",
        "    outputs = D(images)  ## real_img\n",
        "\n",
        "    d_loss_real = criterion(outputs, real_labels)   ## real_img는 real_label로 D학습\n",
        "    real_score = outputs \n",
        "\n",
        "\n",
        "    # (2) fake data끼리 묶어서 D를 학습\n",
        "    z = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
        "    fake_images = G(z)\n",
        "    outputs = D(fake_images)\n",
        "\n",
        "    d_loss_fake = criterion(outputs, fake_labels)   ## fake image를 fake_label로 D학습\n",
        "    fake_score = outputs\n",
        "        \n",
        "        \n",
        "    # D Backprop, Optimize\n",
        "    d_loss = d_loss_real + d_loss_fake    ### (real끼리) + (fake끼리) => sum\n",
        "    reset_grad()\n",
        "    d_loss.backward()  \n",
        "    d_optimizer.step()\n",
        "        \n",
        "        \n",
        "    # ================================================================== #\n",
        "    #                        Train the generator                         #\n",
        "    # ================================================================== #\n",
        "    # G 학습\n",
        "    z = torch.randn(batch_size, latent_size, 1, 1).to(device)   ## latent vector 생성\n",
        "    fake_images = G(z)   ## fake image 생성\n",
        "    outputs = D(fake_images)  ## 생성한 fake image를 D에 넣고 real image로 예측하도록 G를 학습\n",
        "        \n",
        "    g_loss = criterion(outputs, real_labels)  ## fake image를 real_label로 G학습 (D를 속이는 방향)\n",
        "        \n",
        "    # G Backprop, Optimize\n",
        "    reset_grad()\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "        \n",
        "    # Monitoring loss\n",
        "    if (i+1) % 35 == 0:\n",
        "      print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "            .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item()))\n",
        "    \n",
        "  # Save real images\n",
        "  if (epoch+1) == 1:\n",
        "    images = images.reshape(images.size(0), 3, 32, 32)\n",
        "    save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
        "    \n",
        "  # (epoch마다 생성된 영상을 확인하도록) Save fake images\n",
        "  fake_images = fake_images.reshape(fake_images.size(0), 3, 31, 31)\n",
        "  save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
        "\n",
        "# Save the model checkpoints \n",
        "torch.save(G.state_dict(), '/content/drive/MyDrive/Colab_Notebooks/4-1_DL/result/VGAN_IS_car/G.ckpt')\n",
        "torch.save(D.state_dict(), '/content/drive/MyDrive/Colab_Notebooks/4-1_DL/result/VGAN_IS_car/D.ckpt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inception Score\n",
        "- IS = D * S\n",
        "- S (Sharpness) : S가 크다 -> classifier가 확신을 가지고 prediction을 생성 -> predictive distribution  c(y|x)가 low entropy를 갖음\n",
        "- D (Diversity) : D가 크다 -> 다양한 class에 대한 prediction을 생성 -> marginal distribution  c(y)가 high entropy를 갖음"
      ],
      "metadata": {
        "id": "4-tyEVMZcIo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.randn(batch_size, latent_size, 1, 1).to(device)    ## latent vectors 생성\n",
        "fake_images = G(z)   ## fake images 생성\n",
        "fake_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLRZwsnB_zdo",
        "outputId": "8414fe53-da8a-47b5-91df-83607f62445c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 3, 31, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_dataset = F.interpolate(fake_images, size=(299, 299), mode='bilinear')   ## fake images를 inceptionV3 model input size(299,299)로 맞춰 interpolation\n",
        "print(fake_images.shape)  \n",
        "\n",
        "loader = torch.utils.data.DataLoader(fake_images, batch_size=batch_size, num_workers=0, shuffle=False)   ## fake images를 batch로 구성함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrivF6qZ_6h2",
        "outputId": "c01f26a4-58b4-46bd-8177-5048b0abf682"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 3, 31, 31])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Colab_Notebooks/4-1_DL/result/VGAN_IS_car/G.ckpt'\n",
        "generator_model_dict = torch.load(path, map_location=device)   ## 위에서 학습한 Generator의 best parameter를 불러옴\n",
        "G.load_state_dict(generator_model_dict)    ## best parameter를 적용한 Generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBgqrJZhJCxg",
        "outputId": "8546f749-1fb1-4134-b132-95a7c7066c8a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_gan_metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDc_ky9xbrwP",
        "outputId": "17a03cd7-aa37-4044-9c69-dd4bf60fd58e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch_gan_metrics\n",
            "  Downloading pytorch_gan_metrics-0.5.2-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch_gan_metrics) (23.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch_gan_metrics) (4.65.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pytorch_gan_metrics) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.8.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_gan_metrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_gan_metrics) (0.15.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.2->pytorch_gan_metrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.2->pytorch_gan_metrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.2->pytorch_gan_metrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.2->pytorch_gan_metrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.2->pytorch_gan_metrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.2->pytorch_gan_metrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.2->pytorch_gan_metrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.2->pytorch_gan_metrics) (16.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.2->pytorch_gan_metrics) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.2->pytorch_gan_metrics) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.2->pytorch_gan_metrics) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.2->pytorch_gan_metrics) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.2->pytorch_gan_metrics) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.2->pytorch_gan_metrics) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.2->pytorch_gan_metrics) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.9.2->pytorch_gan_metrics) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.2->pytorch_gan_metrics) (1.3.0)\n",
            "Installing collected packages: pytorch_gan_metrics\n",
            "Successfully installed pytorch_gan_metrics-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_gan_metrics import get_inception_score\n",
        "\n",
        "IS, IS_std  = get_inception_score(loader)   ## Inception Score를 구함\n",
        "print(f\"IS: {round(IS,4)}, IS_std: {round(IS_std,4)} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpPk2DXOAsQO",
        "outputId": "2f5b384a-c958-486d-a9e5-53f11505ba6d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/w86763777/pytorch-gan-metrics/releases/download/v0.1.0/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n",
            "100%|██████████| 91.2M/91.2M [00:00<00:00, 205MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IS: 2.8044, IS_std: 0.3225 \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}